{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import warnings, gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# ktrain\n",
    "import ktrain\n",
    "from ktrain import text\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records:  2038\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>Begins with a story to engage audience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delivery</td>\n",
       "      <td>He clasps his hands a lot while he speaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Delivery</td>\n",
       "      <td>Use of humour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Delivery</td>\n",
       "      <td>Use of analogy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delivery</td>\n",
       "      <td>He makes good eye contact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic                                   Sentence\n",
       "0        No     Begins with a story to engage audience\n",
       "1  Delivery  He clasps his hands a lot while he speaks\n",
       "2  Delivery                              Use of humour\n",
       "3  Delivery                             Use of analogy\n",
       "4  Delivery                  He makes good eye contact"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"TrainingDataForBERTMODEL15-9-Delivery-Binary.csv\", header='infer')\n",
    "# Dropping Null Values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Total Records\n",
    "print(\"Total Records: \", df.shape[0])\n",
    "\n",
    "# Inspect\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split\n",
    "target = ['Topic']\n",
    "data = ['Sentence']\n",
    "\n",
    "X = df[data]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common Parameters\n",
    "max_len = 500\n",
    "batch_size = 16\n",
    "learning_rate = 5e-5\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 11\n",
      "\t95percentile : 28\n",
      "\t99percentile : 52\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 12\n",
      "\t95percentile : 25\n",
      "\t99percentile : 54\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n"
     ]
    }
   ],
   "source": [
    "#########\n",
    "## With Transformer = bert-base-uncased\n",
    "######\n",
    "# Transformer Model\n",
    "model_ = 'bert-base-uncased'\n",
    "t_mod = text.Transformer(model_, maxlen=500, classes = [0,1])\n",
    "\n",
    "\n",
    "'''Converting split data to list [so it can processed]'''\n",
    "#train\n",
    "X_tr = X_train['Sentence'].tolist()\n",
    "y_tr = y_train['Topic'].tolist()\n",
    "\n",
    "#test\n",
    "X_ts = X_test['Sentence'].tolist()\n",
    "y_ts = y_test['Topic'].tolist()\n",
    "\n",
    "\n",
    "# Pre-processing training & test data\n",
    "train = t_mod.preprocess_train(X_tr,y_tr)\n",
    "test = t_mod.preprocess_train(X_ts,y_ts)\n",
    "\n",
    "# Model Classifier\n",
    "model = t_mod.get_classifier()\n",
    "\n",
    "learner = ktrain.get_learner(model, train_data=train, val_data=test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 5e-05...\n",
      "Epoch 1/5\n",
      " 22/115 [====>.........................] - ETA: 2:04:07 - loss: 0.6756 - accuracy: 0.5966"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "learner.fit_onecycle(learning_rate, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Delivery       0.94      0.89      0.91       123\n",
      "          No       0.84      0.91      0.88        81\n",
      "\n",
      "    accuracy                           0.90       204\n",
      "   macro avg       0.89      0.90      0.89       204\n",
      "weighted avg       0.90      0.90      0.90       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "x = learner.validate(class_names=t_mod.get_classes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = ktrain.get_predictor(learner.model, preproc=t_mod)\n",
    "predictor.save('DeliveryBinaryClassifier')\n",
    "print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embeddings_layer_call_and_return_conditional_losses, embeddings_layer_call_fn, encoder_layer_call_and_return_conditional_losses, encoder_layer_call_fn, pooler_layer_call_and_return_conditional_losses while saving (showing 5 of 1070). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "model.save('completeDeliv_saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-809e89b10f69>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PresentationSkillDataSetForBert.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#classes = ['Delivery','Structure','Visual Aids']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclasses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Delivery'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mktrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreproc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt_mod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df1=pd.read_csv(\"PresVideosTo6sentencesusingFullStopasDelimiter.csv\")\n",
    "#classes = ['Delivery','Structure','Visual Aids']\n",
    "classes = ['Delivery','']\n",
    "predictor = ktrain.get_predictor(learner.model, preproc=t_mod)\n",
    "\n",
    "segmentId=df1['SegmentId']\n",
    "segList=list(segmentId)\n",
    "\n",
    "startTime=df1['StartTime']\n",
    "strList=list(startTime)\n",
    "\n",
    "endTime=df1['EndTime']\n",
    "endList=list(endTime)\n",
    "\n",
    "transcript=df1['Transcript']\n",
    "transList=list(transcript)\n",
    "transList1=[]\n",
    "for i in transList:\n",
    "    if i != 'nan':\n",
    "        transList1.append(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "segTranscript=[]\n",
    "allSegmentsTrans=[]\n",
    "while i < len(segList)-2:\n",
    "    #print(segList[i])\n",
    "    #print()\n",
    "    if segList[i]==segList[i+1]:\n",
    "        print(segList[i],'  ==  ',segList[i+1])\n",
    "        print()\n",
    "        segTranscript.append(transList1[i])\n",
    "        #segTranscript.append(transList1[i+1])\n",
    "        print( transList1[i])\n",
    "        #print( transList1[i+1])\n",
    "        print()\n",
    "        i+=1\n",
    "    else:\n",
    "        print(segList[i],'  !=  ',segList[i+1])\n",
    "        print()\n",
    "        \n",
    "        segTranscript.append(transList1[i])\n",
    "        listToString=' '.join([str(item) for item in segTranscript ])\n",
    "        allSegmentsTrans.append([segList[i],strList[i-5],endList[i-5],segTranscript,listToString])\n",
    "        print(listToString)\n",
    "        print()\n",
    "        segTranscript=[]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transList1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8a36a615d3c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'transList1 = '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransList1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransList1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transList1' is not defined"
     ]
    }
   ],
   "source": [
    "#### \n",
    "# Write the annotation result to Excel File\n",
    "\n",
    "import xlrd\n",
    "import xlsxwriter\n",
    "workbook = xlsxwriter.Workbook('PresentationCorpusAnnotatedUsingBertBaseUncase-BinaryD.xlsx')\n",
    "worksheet = workbook.add_worksheet('Sheet1')\n",
    "worksheet.write('A1', 'SegmentId')\n",
    "worksheet.write('B1', 'StartTime')\n",
    "worksheet.write('C1', 'EndTime')\n",
    "worksheet.write('D1', 'Transcript')\n",
    "worksheet.write('E1', 'Topic')\n",
    "row=1\n",
    "col=0\n",
    "\n",
    "\n",
    "for i in allSegmentsTrans:\n",
    "    \n",
    "    worksheet.write(row,col,i[0])\n",
    "    worksheet.write(row,col+1,i[1])\n",
    "    worksheet.write(row,col+2,i[2])\n",
    "    transRow=row\n",
    "    for j in i[3]:\n",
    "        worksheet.write(transRow,col+3,j)\n",
    "        transRow+=1\n",
    "    worksheet.write(row,col+4,predictor.predict(i[4]))\n",
    "        \n",
    "        \n",
    "\n",
    "    row+=transRow  \n",
    "workbook.close()        \n",
    "\n",
    "#pred_class = predictor.predict(transList )\n",
    "#print(\"Predicted Class: \", predictor.predict(transList ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
